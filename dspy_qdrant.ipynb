{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samvardhan/miniconda3/envs/dspy_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://www.thoughtworks.com/en-in/insights/blog/data-strategy/building-an-amazon-com-for-your-data-products\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_contents = [doc.text for doc in documents]\n",
    "doc_ids = list(range(1, len(doc_contents) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77.7M/77.7M [00:06<00:00, 11.1MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.add(\n",
    "    collection_name=\"DSpy_Qdrant\",\n",
    "    documents=doc_contents,\n",
    "    ids=doc_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "import dspy\n",
    "\n",
    "\n",
    "qdrant_retriever_model = QdrantRM(\"DSpy_Qdrant\", client, k=10)\n",
    "\n",
    "\n",
    "ollama_model = dspy.OllamaLocal(model=\"llama2\",model_type='text',\n",
    "                                max_tokens=350,\n",
    "                                temperature=0.1,\n",
    "                                top_p=0.8, frequency_penalty=1.17, top_k=40)\n",
    "\n",
    "\n",
    "dspy.settings.configure(lm= ollama_model, rm=qdrant_retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import deduplicate\n",
    "\n",
    "\n",
    "class SimplifiedBaleen(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "\n",
    "\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Data Mesh?\n",
      "Predicted Answer: Data Mesh is a term used in the context of software development and architecture. It refers to a design pattern or approach where data is distributed across multiple microservices, each responsible for its own subset of data, rather than being centralized in a single monolithic database. This allows for greater scalability, fault tolerance, and flexibility in terms of how data is stored and accessed.\n",
      "\n",
      "In this context, \"Data Mesh\" can be thought of as a network or mesh of interconnected microservices that work together to provide a unified view of the data. Each microservice acts as a node in the mesh, communicating with other nodes to exchange data and maintain consistency across the system. This allows for more efficient use of resources, as well as greater resilience and adaptability in response to changing requirements or conditions.\n",
      "\n",
      "The term \"Data Mesh\" is often used in contrast to traditional monolithic architecture, where all the data is stored in a single database that serves as the source of truth for the entire system. In this approach, changes made to one part of the system can have unintended consequences on other parts of the system, leading to complexity and potential bugs.\n",
      "\n",
      "In contrast, with Data Mesh architecture, each microservice has its own local data store, and updates are made independently without affecting other services. This allows for greater flexibility in terms of how data is stored and accessed, as well as more efficient use of resources since each service only needs to manage its own subset of data.\n",
      "\n",
      "Overall, Data Mesh architecture is a way to design software systems that can scale and adapt to changing requirements while minimizing complexity and potential bugs.\n",
      "Retrieved Contexts (truncated): ['[ ![Thoughtworks](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/thoughtworks-logo.svg) ](/en-in \"Thoughtworks\")\\n\\nMenu\\n\\nClose\\n\\n  * [What we do  ](/en-in/what-we-do \"What we d...']\n"
     ]
    }
   ],
   "source": [
    "my_question = \"What is Data Mesh?\"\n",
    "\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "uncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\n",
    "pred = uncompiled_baleen(my_question)\n",
    "\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event(dspy.Signature):\n",
    "    description = dspy.InputField(\n",
    "        desc=\"Question regarding the content\",\n",
    "    )\n",
    "    summary = dspy.OutputField(desc=\"Summary of the content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventExtractor(dspy.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Retrieve module to get relevant documents\n",
    "        self.retriever = dspy.Retrieve(k=3)\n",
    "        # Predict module for the created signature\n",
    "        self.predict = dspy.Predict(Event)\n",
    "\n",
    "    def forward(self, query: str):\n",
    "        # Retrieve the most relevant documents\n",
    "        results = self.retriever.forward(query)\n",
    "\n",
    "        # Try to extract events from the retrieved documents\n",
    "        events = []\n",
    "        for document in results.passages:\n",
    "            event = self.predict(description=document)\n",
    "            events.append(event)\n",
    "\n",
    "        return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(\n",
       "     summary=\"ThoughtWorks is a global software consulting company that helps clients achieve faster growth through technology and innovation. They offer a range of services including data strategy, data engineering, cloud computing, and more. In this summary, we will explore how ThoughtWorks can help organizations achieve faster growth through their expertise in these areas.\\n\\nData Strategy: ThoughtWorks helps clients develop a comprehensive data strategy that aligns with their business goals. They provide services such as data governance, data quality, and data integration to ensure that clients have a solid foundation for their data-driven initiatives. By leveraging the power of data, organizations can make more informed decisions, improve customer experiences, and gain a competitive advantage.\\n\\nData Engineering: ThoughtWorks' expertise in data engineering enables them to design and implement scalable and secure data pipelines that meet clients' needs. They help clients integrate their systems, processes, and tools to create a seamless data flow. By streamlining the data engineering process, organizations can reduce costs, improve efficiency, and enhance decision-making capabilities.\\n\\nCloud Computing: ThoughtWorks helps clients migrate to cloud computing platforms that meet their specific needs. They provide services such as cloud architecture design, migration planning, and ongoing management to ensure that clients get the most out of their cloud investment. By leveraging the scalability and flexibility of cloud computing, organizations can improve agility, reduce costs, and enhance innovation capabilities.\\n\\nIn summary, ThoughtWorks offers a range of services designed to help organizations achieve faster growth through technology and innovation. By providing expertise in data strategy\"\n",
       " )]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = EventExtractor()\n",
    "extractor.forward(\"What is Data Mesh ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['[ ![Thoughtworks](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/thoughtworks-logo.svg) ](/en-in \"Thoughtworks\")\\n\\nMenu\\n\\nClose\\n\\n  * [What we do  ](/en-in/what-we-do \"What we do\")\\n\\n    * [ Go to overview ](/en-in/what-we-do)\\n      * ### Services\\n\\n        * [ Artificial Intelligence  ](/en-in/what-we-do/ai)\\n        * [ Cloud  ](/en-in/what-we-do/cloud)\\n        * [ Customer Experience and Products  ](/en-in/what-we-do/customer-experience-product-design)\\n        * [ Data and Analytics  ](/en-in/what-we-do/data)\\n        * [ Managed Services  ](/en-in/what-we-do/digital-application-management-and-operations)\\n        * [ Modernization  ](/en-in/what-we-do/modernization)\\n        * [ Platforms  ](/en-in/what-we-do/platforms)\\n\\n  * [Who we work with  ](/en-in/clients \"Who we work with\")\\n\\n    * [ Go to overview ](/en-in/clients)\\n    * [Automotive  ](/en-in/clients/automotive \"Automotive\")\\n    * [Healthcare and Life Sciences  ](/en-in/clients/healthcare \"Healthcare and Life Sciences\")\\n    * [Public Sector  ](/en-in/clients/public-sector \"Public Sector\")\\n    * [Cleantech, Energy and Utilities  ](/en-in/clients/cleantech-energy-utilities \"Cleantech, Energy and Utilities\")\\n    * [Media and Publishing  ](/en-in/clients/media-publishing \"Media and Publishing\")\\n    * [Retail and E-commerce  ](/en-in/clients/retail-ecommerce \"Retail and E-commerce\")\\n    * [Financial Services and Insurance  ](/en-in/clients/financial-services-insurance \"Financial Services and Insurance\")\\n    * [Not-for-profit  ](/en-in/clients/not-for-profit \"Not-for-profit\")\\n    * [Travel and Transport  ](/en-in/clients/travel-transport \"Travel and Transport\")\\n\\n  * [Insights  ](/en-in/insights \"Insights\")\\n\\n    * [ Go to overview ](/en-in/insights)\\n      * Loading\\n\\n###\\n\\n      * ### Resource Hubs\\n\\n        * [ Technology \\n\\nEnterprise technology and engineering excellence\\n\\n](/en-in/insights/technology)\\n\\n        * [ Business \\n\\nBusiness and industry insights for digital leaders\\n\\n](/en-in/insights/business)\\n\\n        * [ Culture \\n\\nExplore what it means to be a Thoughtworker\\n\\n](/en-in/insights/culture)\\n\\n      * ### Publications and Tools\\n\\n        * [ Technology Radar \\n\\nAn opinionated guide to today\\'s technology landscape\\n\\n](/en-in/radar)\\n\\n        * [ Perspectives \\n\\nA no-nonsense publication for digital leaders\\n\\n](/en-in/perspectives)\\n\\n        * [ Digital Fluency Model \\n\\nA model to help you build a resilient business\\n\\n](/en-in/digital-fluency)\\n\\n        * [ Decoder \\n\\nThe business execs\\' A-Z guide to technology\\n\\n](/en-in/insights/decoder)\\n\\n        * [ Looking Glass \\n\\nBringing the tech-led business changes into focus\\n\\n](/en-in/insights/looking-glass)\\n\\n      * ### All Insights\\n\\n        * [ Articles \\n\\nIn-depth insights to help your business grow\\n\\n](/en-in/insights/articles)\\n\\n        * [ Blogs \\n\\nExpert advice on strategy, design, engineering, and careers\\n\\n](/en-in/insights/blog)\\n\\n        * [ Books \\n\\nExplore our extensive library to keep learning\\n\\n](/en-in/insights/books)\\n\\n        * [ Podcasts \\n\\nConversations on the latest in business and tech\\n\\n](/en-in/insights/podcasts)\\n\\n  * [Careers  ](/en-in/careers \"Careers\")\\n\\n    * [ Go to overview ](/en-in/careers)\\n    * [Application Process \\n\\nWhat to expect as you interview with us\\n\\n](/en-in/careers/our-process \"Application Process\")\\n\\n    * [Consultant Life \\n\\nLearn what life is like as a Thoughtworker\\n\\n](/en-in/careers/consultant-life \"Consultant Life\")\\n\\n    * [Thoughtworks India graduates hiring  ](/en-in/careers/graduates \"Thoughtworks India graduates hiring\")\\n    * [Search Jobs \\n\\nFind open positions in your region\\n\\n](/en-in/careers/jobs \"Search Jobs\")\\n\\n    * [Stay Connected \\n\\nSign up for our monthly newsletter\\n\\n](/en-in/careers/access \"Stay Connected\")\\n\\n    * [Learning and Development \\n\\nExplore how we support career growth\\n\\n](/en-in/careers/learning-and-development \"Learning and Development\")\\n\\n    * [Benefits \\n\\nSee how we take care of our people\\n\\n](/en-in/careers/benefits \"Benefits\")\\n\\n  * [About  ](/en-in/about-us \"About\")\\n\\n    * [ Go to overview ](/en-in/about-us)\\n    * [Our Purpose  ](/en-in/about-us/our-purpose \"Our Purpose\")\\n    * [Diversity, Equity and Inclusion  ](/en-in/about-us/diversity-and-inclusion \"Diversity, Equity and Inclusion\")\\n    * [Our History  ](/en-in/about-us/history \"Our History\")\\n    * [Our Leaders  ](/en-in/about-us/leaders \"Our Leaders\")\\n    * [Social Change  ](/en-in/about-us/social-change \"Social Change\")\\n    * [News  ](/en-in/about-us/news \"News\")\\n    * [Partnerships  ](/en-in/about-us/partnerships \"Partnerships\")\\n    * [Sustainability  ](/en-in/about-us/sustainability \"Sustainability\")\\n    * [Conferences and Events  ](/en-in/about-us/events \"Conferences and Events\")\\n    * [Our Brand  ](/en-in/about-us/brand \"Our Brand\")\\n    * [Awards and Recognition  ](/en-in/about-us/awards-recognition \"Awards and Recognition\")\\n\\n  * [Investors  ](https://investors.thoughtworks.com/ \"Investors\")\\n  * [Contact  ](/en-in/contact-us \"Contact\")\\n\\nSearch\\n\\nClose\\n\\n![](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/in.svg) India | English\\n\\n  * ![Australia flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/au.svg) Australia\\n\\n[English](/en-au/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![Brazil flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/br.svg) Brazil\\n\\n[English](/en-br/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\") | [Português](/pt-br \"Português\")\\n\\n  * ![Canada flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/ca.svg) Canada\\n\\n[English](/en-ca/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![Chile flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/cl.svg) Chile\\n\\n[English](/en-cl/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\") | [ Español](/es-cl \" Español\")\\n\\n  * ![China flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/cn.svg) China\\n\\n[Hong Kong SAR (English)](/en-cn/insights/blog/data-strategy/building-an-\\namazon-com-for-your-data-products \"Hong Kong SAR \\\\(English\\\\)\") | [Mainland\\n(Chinese)](/zh-cn \"Mainland \\\\(Chinese\\\\)\")\\n\\n  * ![Ecuador flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/ec.svg) Ecuador\\n\\n[English](/en-ec/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\") | [ Español](/es-ec \" Español\")\\n\\n  * ![Germany flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/de.svg) Germany\\n\\n[English](/en-de/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\") | [Deutsch](/de-de \"Deutsch\")\\n\\n  * ![India flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/in.svg) India\\n\\n[English](/en-in/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![Singapore flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/sg.svg) Singapore\\n\\n[English](/en-sg/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![Spain flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/es.svg) Spain\\n\\n[English](/en-es/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\") | [ Español](/es-es \" Español\")\\n\\n  * ![Thailand flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/th.svg) Thailand\\n\\n[English](/en-th/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![United Kingdom flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/gb.svg) United Kingdom\\n\\n[English](/en-gb/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![United States flag](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/us.svg) United States\\n\\n[English](/en-us/insights/blog/data-strategy/building-an-amazon-com-for-your-\\ndata-products \"English\")\\n\\n  * ![Worldwide icon](/etc.clientlibs/thoughtworks/clientlibs/clientlib-site/resources/images/global.svg) Worldwide\\n\\n[English](/insights/blog/data-strategy/building-an-amazon-com-for-your-data-\\nproducts \"English\")\\n\\n![](/content/dam/thoughtworks/images/photography/banner-\\nimage/insights/in_banner_blogs.jpg)\\n![](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n#  Building An “Amazon.com” For Your Data Products\\n\\nSurfacing reliability SLIs and SLOs can boost adoption. Here’s how.\\n\\n[ Blogs Back ](/en-in/insights/blog) [ Blogs Back ](/en-in/insights/blog)\\n\\n![Social share button](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/share-fill.svg)\\n\\nClose\\n\\n[ Data strategy ](https://www.thoughtworks.com/insights/topic/data-strategy) [\\nData mesh ](https://www.thoughtworks.com/insights/topic/data-mesh) [ Blog\\n](/en-in/insights/blog)\\n\\nBy\\n\\n[Barr Moses](/en-in/profiles/b/barr-moses) ,\\n\\n[Manisha Jain](/en-in/profiles/m/manisha-jain)  and\\n\\n[Pablo Porto](/en-in/profiles/p/pablo-porto)\\n\\nPublished: June 20, 2023\\n\\n![Customer 360 Data\\nProduct](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_1.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n![Customer 360 Data\\nProduct](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_1.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nHave you ever come across an internal [data\\nproduct](https://www.thoughtworks.com/en-us/what-we-do/data-and-ai/modern-\\ndata-engineering-playbook/data-as-a-product) and side-eyed it like it’s your\\nkid’s prom date? While it _seems_ like it fits the requirements, you don’t\\nquite trust it — who knows where the data in this shifty table has been. Will\\nit be reliable and safe even after you turn your focus elsewhere? Will the\\nschema stay true?\\n\\nThis project is your baby; you just can’t risk it. So, just to be safe you\\ntake the extra time to recreate the dataset.\\n\\n## Data products and trustworthiness\\n\\nAccording to Zhamak Dehgahi, data products should be discoverable,\\naddressable, trustworthy, self-describing, interoperable and secure. In our\\nexperience, most data products only support one or two use cases. That’s a\\nlost opportunity experienced by too many data teams, especially those with\\ndecentralized organizational structures or implementing [data\\nmesh](https://www.montecarlodata.com/blog-what-is-a-data-mesh-and-how-not-to-\\nmesh-it-up/).\\n\\n![Data product characteristics as originally defined by Zhamak Dehghani.\\n](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_2.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nData product characteristics as originally defined by Zhamak Dehghani.\\n\\n![Data product characteristics as originally defined by Zhamak Dehghani.\\n](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_2.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nData product characteristics as originally defined by Zhamak Dehghani.\\n\\nIn the focus on building data trust with business stakeholders, it’s easy to\\nlose sight of the importance of also building trust with data teams across\\ndifferent domains. However, a data product must be trustworthy if it’s to\\nencourage the reuse of data products. This is what ultimately **separates data\\nmesh from data silo.**\\n\\nThe data product is trustworthy if data consumers are confident in the\\naccuracy and reliability of the data. Data products should be transparent with\\nregards to information quality metrics and performance promises.\\n\\nCreating a central marketplace or catalog of internal data products is a great\\nfirst step to raising awareness, but more is needed to convince skeptical data\\nconsumers to actually start using them.\\n\\nFor this, we can take a page out of Amazon.com’s playbook. Amazon provides an\\nincredible amount of detail to help consumers purchase products from unknown\\nthird-parties. Take the example of something as simple as a wrench:\\n\\n[\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_3.png)\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg) I’d buy this wrench.\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_3.png)\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg) I’d buy this wrench.\\n](https://www.amazon.com/Amazon-Brand-Denali-8-Inch-\\nAdjustable/dp/B091BLK385/ref=sr_1_1_ffob_sspa?crid=39GIJHE50YBB1&keywords=wrench&qid=1681395714&sprefix=wrench%2Caps%2C70&sr=8-1-spons&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUE1RDdMRDJXTFMxWEkmZW5jcnlwdGVkSWQ9QTAzMzY4NDQzT0NYSFNPR1A3OFZOJmVuY3J5cHRlZEFkSWQ9QTAxODYxODQxMVZDUzkyNlM4TFFRJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ&th=1)\\n\\nIt’s not just a _wrench_ — it’s an adjustable Denali, 7.7 inch, 4.4 ounce,\\nrust resistant steel, adjustable wrench for repairs, maintenance and general\\nuse, covered by a limited lifetime warranty. Oh, and here are similar products\\nand reviews from users like yourself.\\n\\nData teams and data product owners need to be as capable of marketing data\\nproducts as they are at building them. Otherwise, you’re not going to see the\\nadoption levels that justify the value of your data initiative.\\n\\nThe central “store” for your data products needs to include not just\\ninformation about the data, but information about the context of how it can be\\nused. In other words, it needs to provide metrics such as uptime or data\\nfreshness; these are commonly referred to as service level objectives (SLO)\\n\\n  \\n  \\n\\nThoughtworks has helped create one of the more [advanced deployments of Monte\\nCarlo — ](https://www.thoughtworks.com/en-th/insights/blog/data-strategy/dev-\\nexperience-data-mesh-platform)a data observability platform that monitors the\\nhealth and quality of data —[ within a data mesh\\nimplementation](https://www.thoughtworks.com/en-th/insights/blog/data-\\nstrategy/dev-experience-data-mesh-platform).\\n\\nIn this post, we will explore the process of implementation and go further by\\nexploring what else is possible.\\n\\n##  \\n  \\nWhere to start: Identifying reusable data products\\n\\nThe two best ways to fail at creating valuable, reusable data products are to\\ndevelop them without any sense of who they are for and to make them more\\ncomplicated than they need to be.\\n\\nOne of the best ways to succeed is by involving business and product\\nleadership and identifying the most valuable and shared use cases.\\nThoughtworks, for example, often identifies potential data products by working\\nbackwards from the use case using the [Jobs to be done\\n(JTBD)](https://jtbd.info/2-what-is-jobs-to-be-done-jtbd-796b82081cca)\\nframework created by Clayton Christensen.\\n\\n![Example JTBD framework for a Customer 360 data product. Image courtesy of\\nthe\\nauthors.](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_4.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nExample JTBD framework for a Customer 360 data product. Image courtesy of the\\nauthors.\\n\\n![Example JTBD framework for a Customer 360 data product. Image courtesy of\\nthe\\nauthors.](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_4.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nExample JTBD framework for a Customer 360 data product. Image courtesy of the\\nauthors.\\n\\nAnother strategy is to evaluate the [data\\nlineage](https://www.montecarlodata.com/blog-data-lineage/) within your\\ncurrent environment. It’s likely that your tables will follow some sort of\\nPareto distribution where 20% will have 80% of the queries run against them\\n(or power 80% of the most-visited dashboards).\\n\\nFor example, if the table customer_accounts is constantly being queried by\\nmarketing, finance, support and other domains, that can be taken as a signal\\nthat building a data product that consolidates the necessary information into\\na full 360 view may have shared utility.\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_5.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_5.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n## Second step: Creating data product SLOs\\n\\n##\\n\\nA key part of data product thinking is keeping the consumers at the center and\\nconsidering what provides the most value for them. The only way to ensure we\\nare delivering high-quality data products is to identify those consumers,\\nunderstand their requirements and codify their expectations within a [SLO/SLI\\nframework](https://www.thoughtworks.com/en-us/insights/articles/data-mesh-in-\\npractice-product-thinking-and-development).\\n\\nYou can think of SLOs as measures that remove uncertainty surrounding the data\\nand serve as a primary way to define trustworthiness for its consumers.\\n\\nAs explained in [Zhamak’s Data Mesh\\nbook](https://www.oreilly.com/library/view/data-mesh/9781492092384/), in\\ncontrast to previous approaches to data management, data mesh introduces a\\nfundamental shift in that the owners of data products must communicate and\\nguarantee an acceptable level of quality and trust‐worthiness as it is an\\nimportant characteristic of the data product. This means cleansing and running\\nautomated data integrity tests or data quality monitors at the point the data\\nproducts are created.\\n\\nIf SLOs are breached, the data product team must be notified so they can take\\nremediation measures. Like a typical business contract, data product SLOs will\\nlikely evolve over time based on changing circumstances.\\n\\nThoughtworks uses a discovery exercise during its [data mesh\\nacceleration](https://martinfowler.com/articles/data-mesh-accelerate-\\nworkshop.html#DiscoveringDataProducts) workshop on product usage patterns.\\nThis helps teams collectively brainstorm and understand usage, expectations,\\ntrade-offs and business impact. The outcomes of the exercise are then used to\\ndetermine the various SLOs that need to be set for individual products.\\n\\n![Product usage pattern exercise template. Courtesy of\\nThoughtworks.](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_6.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nProduct usage pattern exercise template. Courtesy of Thoughtworks.\\n\\n![Product usage pattern exercise template. Courtesy of\\nThoughtworks.](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_6.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nProduct usage pattern exercise template. Courtesy of Thoughtworks.\\n\\n## Third step: Implementing the SLOs\\n\\n##\\n\\nDuring the implementation phase of the data product, the data product team\\nwill start by defining the metrics (SLIs) used to measure the SLO.\\n\\nOne common SLI for data products is freshness. In the example from the\\nprevious section, the exercise may reveal the marketing team relies heavily on\\na particular dashboard that supports the monitoring of daily campaign and\\npurchasing behaviors, which means the data needs to be updated every day.\\n\\nThe customer service team, on the other hand, may require hourly updates to\\nbetter engage with customers in real time. In this scenario, it is almost\\ncertainly more efficient to build the data product to be updated hourly to\\nserve both consumer groups rather than build two different data products. The\\nmarketing team isn’t going to complain about having data that is more\\nfrequently updated than they requested after all!\\n\\nSLIs are typically expressed as a percentage over a period of time. In the\\nexample presented earlier, 99% freshness over an hourly interval is the SLI in\\nplace for the Customer 360 data product.\\n\\nIn our example, the team has decided to track data freshness checks based on\\nthe processing timestamp attribute present in the dataset that is served by\\nthe data product: processing_timestamp. To do this, they start by defining a\\n[monitor as code](https://docs.getmontecarlo.com/docs/monitors-as-code) that\\nwill become part of the data product which will support the implementation of\\nthe freshness SLO:\\n\\n    \\n    \\n    namespace: customer-domain\\n    montecarlo:\\n      freshness:\\n        - description: Customer 360 Data Product Freshness Monitor\\n          name:\\xa0 Freshness - Customer 360 Data Product\\n          table: analytics:prod.customer_360_dp.customers\\n          freshness_threshold: 240\\n          schedule:\\n            type: fixed\\n            interval_minutes: 240\\n            start_time: \"2022-09-15T01:00:00\"\\n    \\n\\nThe data team can then automate the deployment of this monitor via the CI/CD\\npipeline using the Monte Carlo CLI:\\n\\n    \\n    \\n    montecarlo monitors apply --namespace customer-domain\\n    \\n\\nThis ensures the monitor to support the SLO is implemented and deployed every\\ntime there is a change via the CI/CD pipeline. The monitor as code\\nfunctionality improves the experience of the data product developer in\\nmaintaining and deploying these monitors at scale using version control  \\n\\nThe stakeholder exercise may also reveal that the Customer 360 data product\\nshould not contain deleted rows in the final table as customers will be marked\\nas active or inactive rather than removed entirely. To ensure this, a custom\\nvolume SLI can be set to monitor and ensure the data product follows this\\nbehavior.\\n\\nFinally, data product users need to be alerted whenever any changes are made\\nto the schema of any tables within or upstream of the data product. This is\\nbecause such changes could break processes downstream; there could be new\\nfields that can enable new use cases. This can be covered by an automated\\nschema monitor which sends alerts via the appropriate communication channel.\\n\\n## Going beyond basic SLOs\\n\\n##\\n\\nSo far we have covered three basic dimensions that can be used as SLOs. There\\nare several other dimensions improving data product trust such as accuracy and\\navailability. These and others are described in the [Implementing Service\\nLevel Objectives book](https://www.oreilly.com/library/view/implementing-\\nservice-level/9781492076803/).\\n\\nMore advanced SLOs can better validate data product quality and encourage\\nwider use throughout the organization.\\n\\nFor example, let\\'s imagine the data in our Customer 360 data product is not\\ncomplete. Perhaps our stakeholder exercise revealed the channel and region\\nwhere the customer buys the product is important for the marketing team’s\\ndigital advertising decisions while the customer service team cares deeply\\nthat every customer has a profile in the system.\\n\\nWe could use field health monitors on relevant fields within the data product\\nsuch as region and purchase_channel to surface the number of anomalies over a\\ncertain time period on the attributes the marketing team needs to segment\\nusers. If any of these fields experience anomalous NULL rates or values\\noutside the typical distribution, remediations can be launched to ensure\\ncompliance with stated SLOs. Similarly, we could place field health monitors\\non the account_id field to ensure it is never NULL so that the data product\\nperforms to the customer service team’s standards.\\n\\nDeploying field health monitors has the added benefit of profiling the data,\\nwhich can provide additional context that helps encourage adoption for those\\nnot as familiar with the data or the data product.\\n\\nWhat the field profile feature looks like:\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_7.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_7.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nLet’s look at another possible SLO related to data quality. Consider a\\npurchase order data product tracking the purchases/transactions made by the\\ncustomer. This data product is used as a source for Customer 360 data product\\nto understand the purchase patterns of the customer based on a\\npurchase_timestamp.\\n\\n  \\nUsing a [dimension distribution\\nmonitor](https://docs.getmontecarlo.com/docs/understanding-dimension-tracking-\\nmonitors), we can identify a potential anomaly when an active customer does\\nnot have any purchases made in the recent timeline, highlighting the lack of\\ndata trust/quality on the upstream purchase order data product.\\n\\n### Other indicators to build data trust\\n\\n###\\n\\nAt this point, we have reassured any potential data product users that there\\nare no freshness, volume, schema, or data quality issues that will prevent\\nthem from benefiting from its use. But what other information can we surface\\nthat will speak to the data product’s trustworthiness?\\n\\nOne idea is to go beyond describing the data itself to surfacing information\\non its level of support and consumption. To harken back to our Denali wrench\\nexample, the Amazon.com page doesn’t just describe the product itself, it also\\nincludes information on the lifetime warranty. Netflix doesn’t just tell its\\nviewers the plot of the movie, it also has a list of the top ten most popular.\\n\\nThe data product equivalents of this are:\\n\\n  * **Total tests or custom monitors** : If there are more dbt tests across a pipeline or it has more Monte Carlo custom monitors set, this indicates more granular support and reliability in depth.\\n\\n  * **Coverage percentage:** Data products typically involve a series of complex, interdependent operations upstream. Data moves and is transformed from table to table. Understanding that a data product has basic data monitoring coverage across its [data lineage](https://www.montecarlodata.com/blog-data-lineage/) helps further build trust.\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_8.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_8.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n  * **Average time to response/fixed:** The overview above, currently at the domain level, highlights important metrics to consider when monitoring the health of the data products. Similar to the stability metrics in the DORA 4 key metrics framework, the metrics shown in this overview, “Time to response” and “Time to Fixed,” indicate how long it takes a data product team to spot and recover from any type of incident that could lead to breaching the SLOs. Faster response and fix times indicate data product stability and highlights the maturity of the supporting data product teams thus increasing the trustworthiness over time. \\n\\n  * **Key asset score:** An all too common story is when a member of the data team leverages a seemingly ideal table or data product as part of their task, only later to find out it’s been deprecated or an older version. Monte Carlo\\'s [Key Asset Score, calculated by the ](https://docs.getmontecarlo.com/docs/key-assets-importance-score)reads and writes and the downstream consumption on each dataset part of the data product, can give data product users (and re-users) confidence the asset is safe to use. It can also be helpful for data product owners to measure their success, in a data mesh context, based on the satisfaction and growth of their data product consumers.\\n\\n## Fourth step: Monitoring and visualizing data product SLO health\\n\\n##\\n\\nThe data product teams select what SLOs their data products guarantee, and\\nultimately they are responsible for the satisfaction of their data products’\\nconsumers. To succeed on this, they need the right tools to monitor and track\\nthe SLOs over time.\\n\\nMonte Carlo\\'s notification mechanism enables this by notifying the data\\nproduct teams on any SLO breach incident. To improve the developer experience,\\nthese notifications can also be defined as\\n[code](https://docs.getmontecarlo.com/docs/notifications-as-code) in the\\nlatest version of Monte Carlo and be included as part of the CI/CD pipeline.\\n\\nMonte Carlo also provides functionality to extract some or all of this\\nmonitoring metadata via APIs to publish them in catalogs like\\n[Collibra](https://www.collibra.com/us/en), [dataworld](https://data.world),\\nor [Atlan](https://atlan.com). This is critical for making data products\\ndiscoverable. It’s also where all of the work your team has done to create and\\nautomatically monitor SLOs and SLIs comes together and is put on display.\\n\\nData product owners and data platform teams can leverage these APIs to\\nvisualize the health of the data products in the marketplace via custom\\nintegrations similar to the solution shared in a [past\\nwebinar](https://vimeo.com/765878759).\\n\\n![Service Example - \\\\(4\\\\) Check and show service levels Delivering data\\nproduct health information as part of the user\\nexperience](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_9.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\n![Service Example - \\\\(4\\\\) Check and show service levels Delivering data\\nproduct health information as part of the user\\nexperience](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_9.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nFinally, if you are using dbt for modeling and transforming for your data,\\n[Monte Carlo offers a dbt integration\\n](https://docs.getmontecarlo.com/docs/dbt-integration)that automates the\\nincident creation on every dbt test failure. This provides a holistic view of\\nincidents created due to data quality tests failing for a data served by the\\ndata product, provides our data quality health of the data product and also\\neases debugging. By enabling this integration, the team can leverage Monte\\nCarlo’s notification channel to also receive alerts on data quality issues.\\n\\nTo implement this, the data product team can run the dbt data quality test as\\npart of their data pipeline and upload the results to Monte Carlo with a\\nsimple CLI command.\\n\\n    \\n    \\n    > dbt test\\n    > montecarlo import dbt-run \\\\\\n            --manifest ./target/manifest.json\\xa0 \\\\\\n            --run-results ./target/run_results.json \\\\\\n            --project-name customer-360-data-product\\n    \\n\\n## Putting it all together\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_10.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nSource: Montecarlo\\n\\n![](/content/dam/thoughtworks/images/infographic/Tw_illustration_blog_montecarlo_10.png)\\n\\n![Pause](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/pause-icon.svg)\\n![Play](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/play-icon.svg)\\n\\nSource: Montecarlo\\n\\nThe data mesh principles, especially the data as a product concept can create\\ntremendous business value.\\n\\nDefining SLOs will help build reliable data products that fit business user\\nneeds and surfacing their value will create the level of data trust required\\nfor data driven organizations to thrive.\\n\\nUltimately, the more product context you provide for data consumers and team\\nmembers across the organization, the more efficiencies and value you will be\\nable to derive from a “build once use many times” approach. Good luck!\\n\\n## _Appendix:_\\n\\nData Mesh Accelerated workshop formulated by Paulo Caroli as explained in this\\narticle <https://martinfowler.com/articles/data-mesh-accelerate-workshop.html>\\n\\nhelps teams and organizations accelerate their Data Mesh transformation, by\\nunderstanding their current state and exploring what the next steps will look\\nlike.\\n\\nDisclaimer: The statements and opinions expressed in this article are those of\\nthe author(s) and do not necessarily reflect the positions of Thoughtworks.\\n\\n## Related blogs\\n\\n[\\n![](/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_028.jpg)\\n![](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)\\nData mesh Data Mesh in practice: Getting off to the right start Learn more\\n](/en-in/insights/articles/data-mesh-in-practice-getting-off-to-the-right-\\nstart)\\n\\n[\\n![](/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_070.jpg)\\n![](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)\\nData strategy Data Mesh in practice: Organizational operating model Learn more\\n](/en-in/insights/articles/data-mesh-in-practice-organizational-operating-\\nmodel)\\n\\n[\\n![](/content/dam/thoughtworks/images/photography/abstract/insights/blog/abs_blogs_038.jpg)\\n![](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)\\nData engineering Data Mesh at Glovo  Learn more ](/en-in/insights/blog/data-\\nengineering/data-mesh-at-glovo)\\n\\n## How can you achieve faster growth?\\n\\n[ Connect with us ](/en-in/contact-us)\\n\\nCompany\\n\\n  * [About us](/en-in/about-us)\\n  * [What we do](/en-in/what-we-do)\\n  * [Partnerships](/en-in/about-us/partnerships)\\n  * [Who we work with](/en-in/clients)\\n  * [News](/en-in/about-us/news)\\n  * [Diversity, Equity and Inclusion](/en-in/about-us/diversity-and-inclusion)\\n  * [Careers](/en-in/careers)\\n  * [Investors](https://investors.thoughtworks.com/)\\n  * [Contact us](/en-in/contact-us)\\n\\nInsights\\n\\n  * [Articles](/en-in/insights/articles)\\n  * [Blogs](/en-in/insights/blog)\\n  * [Books](/en-in/insights/books)\\n  * [Podcasts](/en-in/insights/podcasts)\\n\\nSite info\\n\\n  * [Privacy policy](/en-in/about-us/privacy-policy)\\n  * [Accessibility statement](/en-in/about-us/accessibility)\\n  * [Modern slavery statement](/content/dam/thoughtworks/documents/guide/tw_guide_modern_slavery_statement.pdf)\\n  * [Corporate Social Responsibility Policy](/content/dam/thoughtworks/documents/guide/tw_guide_csrpolicy_india.pdf)\\n  * [Policy of Equal Opportunity, Non-Discrimination and Anti-Harassment at the Workplace](/content/dam/thoughtworks/documents/guide/tw_guide_policy_of%20_equal_opportunity_non_discrimination_anti_harassment_india.pdf)\\n  * [Code of conduct](/content/dam/thoughtworks/documents/guide/tw_guide_code_of_conduct_en.pdf)\\n  * [Integrity helpline](https://integrity.thoughtworks.com)\\n\\nConnect with us\\n\\n[ ](https://www.linkedin.com/company/thoughtworks \"Link to Thoughtworks\\nLinkedin page\") [ ](https://www.facebook.com/Thoughtworks \"Link to\\nThoughtworks Facebook page\") [ ](https://www.twitter.com/thoughtworks \"Link to\\nThoughtworks Twitter account\") [ ](javascript: \"Link to Thoughtworks China\\nWeChat subscription account QR code\")\\n\\n[×](javascript:void\\\\(0\\\\);) WeChat\\n\\n![QR code to Thoughtworks China WeChat subscription\\naccount](/etc.clientlibs/thoughtworks/clientlibs/clientlib-\\nsite/resources/images/wechat_qr_code.jpg)\\n\\n[ ](https://www.youtube.com/user/thoughtworks \"Link to Thoughtworks Youtube\\npage\") [ ](https://www.instagram.com/thoughtworks/ \"Link to Thoughtworks\\nInstagram page\")\\n\\n© 2024 Thoughtworks, Inc.\\n\\n'],\n",
       "    answer='Data Mesh is a term used in the context of software development and architecture. It refers to a design pattern or approach where data is distributed across multiple microservices, each responsible for its own subset of data, rather than having a single centralized repository for all data. This allows for greater scalability, fault tolerance, and resilience in the system as a whole.\\n\\nThe term \"Data Mesh\" was popularized by Martin Fowler in his book \"Distributed Systems\". He described it as a way to organize distributed systems around data, rather than around functions or processes. The idea is that each microservice in the mesh has its own local view of the data, and these views are combined to form a global view of the system.\\n\\nThe benefits of Data Mesh include:\\n\\n1. Scalability: By distributing data across multiple microservices, it becomes easier to scale individual services without affecting the entire system.\\n2. Fault tolerance: If one microservice fails, the other services in the mesh can continue to operate and maintain their local views of the data.\\n3. Resilience: Data Mesh allows for more flexible and adaptive systems, as changes or failures in one part of the system do not necessarily impact the entire system.\\n4. Improved data management: By distributing data across multiple services, it becomes easier to manage and maintain consistency across different parts of the system.\\n5. Enhanced security: With Data Mesh, each microservice has its own local view of the data, which can help to reduce the risk of unauthorized access or tampering with sensitive information.\\n\\nOverall,'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAG()\n",
    "rag.forward(\"What is Data Mesh ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.42k/6.42k [00:00<00:00, 10.3MB/s]\n",
      "Downloading readme: 100%|██████████| 9.19k/9.19k [00:00<00:00, 6.95MB/s]\n",
      "Downloading data: 100%|██████████| 566M/566M [02:05<00:00, 4.51MB/s]\n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:18<00:00, 2.60MB/s]\n",
      "Downloading data: 100%|██████████| 46.2M/46.2M [00:10<00:00, 4.27MB/s]\n",
      "Downloading data files: 100%|██████████| 3/3 [03:14<00:00, 64.92s/it]\n",
      "Generating train split: 100%|██████████| 90447/90447 [00:15<00:00, 5835.65 examples/s]\n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:01<00:00, 6005.61 examples/s]\n",
      "Generating test split: 100%|██████████| 7405/7405 [00:01<00:00, 6410.27 examples/s]\n",
      "/Users/samvardhan/miniconda3/envs/dspy_env/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Example({self.data})\"\n",
    "\n",
    "# Define the training set using the Example class\n",
    "answer_golden_set = [\n",
    "    Example({'question': 'What are the considerations to design the right data product?', 'answer': 'Key considerations in designing the right data products are its fulfillment to the use case for a given domain, along with compliance to slo and slis, support for output ports based on persona, metadata for discoverability and access and quality aspects to deliver trust.'}),\n",
    "    Example({'question': 'What are tools used in?', 'answer': 'Snowflake, Talend, DBT, Collibra, Monte Carlo, Dataops.live, SOLE, OAM Client libraries'}),\n",
    "    Example({'question': \"According to Zhamak Dehghani's principles, effective data products in a Data Mesh architecture should possess several key qualities. Which of the following options correctly lists these qualities?\", 'answer': 'Discoverable, Addressable, Trustworthy, Self-Describing, Interoperable, and Secure'})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compiled_rag \u001b[38;5;241m=\u001b[39m \u001b[43mteleprompter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_golden_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dspy_env/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:61\u001b[0m, in \u001b[0;36mBootstrapFewShot.compile\u001b[0;34m(self, student, teacher, trainset, valset)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_student_and_teacher(student, teacher)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_predictor_mappings()\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent\u001b[38;5;241m.\u001b[39m_compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dspy_env/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:122\u001b[0m, in \u001b[0;36mBootstrapFewShot._bootstrap\u001b[0;34m(self, max_bootstraps)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m example_idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bootstrapped:\n\u001b[0;32m--> 122\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bootstrap_one_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    125\u001b[0m         bootstrapped[example_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dspy_env/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:178\u001b[0m, in \u001b[0;36mBootstrapFewShot._bootstrap_one_example\u001b[0;34m(self, example, round_idx)\u001b[0m\n\u001b[1;32m    176\u001b[0m         current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m     dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run or to evaluate example \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m due to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n",
      "File \u001b[0;32m~/miniconda3/envs/dspy_env/lib/python3.11/site-packages/dspy/teleprompt/bootstrap.py:158\u001b[0m, in \u001b[0;36mBootstrapFewShot._bootstrap_one_example\u001b[0;34m(self, example, round_idx)\u001b[0m\n\u001b[1;32m    155\u001b[0m     predictor_cache[name] \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mdemos\n\u001b[1;32m    156\u001b[0m     predictor\u001b[38;5;241m.\u001b[39mdemos \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m predictor\u001b[38;5;241m.\u001b[39mdemos \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m example]\n\u001b[0;32m--> 158\u001b[0m prediction \u001b[38;5;241m=\u001b[39m teacher(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m())\n\u001b[1;32m    159\u001b[0m trace \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mtrace\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, predictor \u001b[38;5;129;01min\u001b[39;00m teacher\u001b[38;5;241m.\u001b[39mnamed_predictors():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Example' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "compiled_rag = teleprompter.compile(RAG(), trainset=answer_golden_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
